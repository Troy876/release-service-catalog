---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: add-fbc-contribution
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: |-
    Task to create an internalrequest to add fbc contributions to index images
  params:
    - name: snapshotPath
      description: Path to the JSON string of the mapped Snapshot spec in the data workspace
      type: string
    - name: dataPath
      description: Path to the JSON string of the merged data to use in the data workspace
      type: string
    - name: fromIndex
      type: string
      description: fromIndex value updated by update-ocp-tag task
    - name: targetIndex
      type: string
      description: targetIndex value updated by update-ocp-tag task
    - name: pipelineRunUid
      type: string
      description: The uid of the current pipelineRun. Used as a label value when creating internal requests
    - name: ocpVersion
      type: string
      description: The OCP version for all components in this release
    - name: resultsDirPath
      type: string
      description: Path to the results directory in the data workspace
    - name: ociStorage
      description: The OCI repository where the Trusted Artifacts are stored
      type: string
      default: "empty"
    - name: ociArtifactExpiresAfter
      description: Expiration date for the trusted artifacts created in the
        OCI repository. An empty string means the artifacts do not expire
      type: string
      default: "1d"
    - name: trustedArtifactsDebug
      description: Flag to enable debug logging in trusted artifacts. Set to a non-empty string to enable
      type: string
      default: ""
    - name: orasOptions
      description: oras options to pass to Trusted Artifacts calls
      type: string
      default: ""
    - name: sourceDataArtifact
      type: string
      description: Location of trusted artifacts to be used to populate data directory
      default: ""
    - name: dataDir
      description: The location where data will be stored
      type: string
      default: /var/workdir/release
    - name: taskGitUrl
      type: string
      description: The url to the git repo where the release-service-catalog tasks and stepactions to be used are stored
    - name: taskGitRevision
      type: string
      description: The revision in the taskGitUrl repo to be used
  results:
    - name: buildTimestamp
      description: Build timestamp used in the tag
    - name: mustSignIndexImage
      description: Whether the index image should be signed
    - name: mustPublishIndexImage
      description: Whether the index image should be published
    - name: isFbcOptIn
      description: Indicates whether the FBC fragment is opt-in (true/false)
    - name: requestTargetIndex
      description: The targetIndex used in this request
    - name: requestResultsFile
      description: Internal Request results file
    - name: internalRequestResultsFile
      description: Additional Internal Request results file
    - name: requestMessage
      description: Internal Request message
    - name: requestReason
      description: Internal Request reason
    - name: indexImageDigests
      description: list of manifest digests for each arch from manifest list in index image
    - name: sourceDataArtifact
      type: string
      description: Produced trusted data artifact
  volumes:
    - name: workdir
      emptyDir: {}
  stepTemplate:
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
    env:
      - name: IMAGE_EXPIRES_AFTER
        value: $(params.ociArtifactExpiresAfter)
      - name: "ORAS_OPTIONS"
        value: "$(params.orasOptions)"
      - name: "DEBUG"
        value: "$(params.trustedArtifactsDebug)"
  steps:
    - name: use-trusted-artifact
      computeResources:
        limits:
          memory: 64Mi
        requests:
          memory: 64Mi
          cpu: 30m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/use-trusted-artifact/use-trusted-artifact.yaml
      params:
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(params.sourceDataArtifact)
    - name: add-contribution
      image: quay.io/konflux-ci/release-service-utils:0f82be4be43294b6a96846d87ef7f7c0b9e34267
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi  # was exiting with code 137 when set to 256Mi
          cpu: 200m
      script: |
        #!/usr/bin/env bash
        #
        set -eo pipefail

        SNAPSHOT_PATH="$(params.dataDir)/$(params.snapshotPath)"
        DATA_FILE="$(params.dataDir)/$(params.dataPath)"
        if [ ! -f "${DATA_FILE}" ] ; then
            echo "No valid data file was provided."
            exit 1
        fi

        # adding a new result as modifying the current one used breaks e2e for single component.
        # to be handled in RELEASE-1640.
        RESULTS_FILE="$(params.resultsDirPath)/internal-requests-results.json"
        echo -n "$RESULTS_FILE" > "$(results.internalRequestResultsFile.path)"
        RESULTS_FILE="$(params.dataDir)/$(params.resultsDirPath)/internal-requests-results.json"

        echo -n "$(params.dataDir)/$(params.pipelineRunUid)/ir-$(context.taskRun.uid)-result.json" \
          > "$(results.requestResultsFile.path)"

        default_build_timeout_seconds="3600"
        default_request_timeout_seconds="3600"

        hotfix=$(jq -r '.fbc.hotfix // "false"' "${DATA_FILE}")
        pre_ga=$(jq -r '.fbc.preGA // "false"' "${DATA_FILE}")
        staged_index=$(jq -r '.fbc.stagedIndex // "false"' "${DATA_FILE}")
        product_name=$(jq -r '.fbc.productName // ""' "${DATA_FILE}")
        product_version=$(jq -r '.fbc.productVersion // ""' "${DATA_FILE}")
        build_timeout_seconds=$(jq -r --arg build_timeout_seconds ${default_build_timeout_seconds} \
            '.fbc.buildTimeoutSeconds // $build_timeout_seconds' "${DATA_FILE}")
        request_timeout_seconds=$(jq -r --arg request_timeout_seconds ${default_request_timeout_seconds} \
            '.fbc.requestTimeoutSeconds // $request_timeout_seconds' "${DATA_FILE}")
        internal_request_service_account=$(jq -r '.fbc.internalRequestServiceAccount // "release-service-account"' \
            "${DATA_FILE}")

        if [ "${staged_index}" = "true" ]; then
          iib_service_account_secret="iib-service-account-stage"
        else
          iib_service_account_secret="iib-service-account-prod"
        fi
        publishing_credentials=$(jq -r '.fbc.publishingCredentials // "catalog-publishing-secret"' "$DATA_FILE")

        timestamp_format=$(jq -r '.fbc.timestampFormat // "%s"' "${DATA_FILE}")
        timestamp=$(date "+${timestamp_format}")

        # default target_index
        target_index=$(params.targetIndex)

        if [ "${hotfix}" = "true" ] && [ "${pre_ga}" = "true" ]; then
          echo "fbc.preGA and fbc.hotfix are mutually exclusive. Please set just one in the ReleasePlanAdmission"
          exit 1
        fi

        # the target_index is modified when the pipelinerun is a for `hotfix` or a `pre-GA` release
        if [ "${hotfix}" = "true" ]; then
          issue_id=$(jq -r '.fbc.issueId // empty' "${DATA_FILE}")
          if [ -z "${issue_id}" ]; then
            echo "Hotfix releases requires the issue id set in the 'fbc.issueId' key of the ReleasePlanAdmission " \
                 "spec.data field"
            exit 1
          fi
          target_index="${target_index}-${issue_id}-${timestamp}"
        elif [ "${pre_ga}" = "true" ]; then
          if [ -z "${product_name}" ] || [ -z "${product_version}" ]; then
            echo "Pre-GA releases require 'fbc.productName' and 'fbc.productVersion' set in the ReleasePlanAdmission " \
                 "spec.data field"
            exit 1
          fi
          target_index="${target_index}-${product_name}-${product_version}-${timestamp}"
        fi

        # to keep compatibility with current single component mode
        echo -n "$timestamp" > "$(results.buildTimestamp.path)"
        echo -n "$target_index" > "$(results.requestTargetIndex.path)"
        jq -n --arg target_index "$target_index" \
          '{"index_image": {"target_index": $target_index}, "components": []}' \
          | tee "$RESULTS_FILE"

        pipelinerun_label="internal-services.appstudio.openshift.io/pipelinerun-uid"

        # Create batch with all fragments - simplified approach
        LENGTH=$(jq -r '.components | length' "${SNAPSHOT_PATH}")
        echo "Creating single batch with all $LENGTH components..."

        # Read global buildTags and addArches from data file
        build_tags=$(jq '.fbc.buildTags // []' "${DATA_FILE}")
        add_arches=$(jq '.fbc.addArches // []' "${DATA_FILE}")

        # Apply target_index resolution logic for hotfix/pre-GA
        resolved_target_index="$(params.targetIndex)"  # Use original targetIndex parameter
        if [ "${hotfix}" = "true" ]; then
          issue_id=$(jq -r '.fbc.issueId // empty' "${DATA_FILE}")
          if [ -z "${issue_id}" ]; then
            echo "Hotfix releases requires the issue id set in the 'fbc.issueId' key of the ReleasePlanAdmission " \
                 "spec.data field"
            exit 1
          fi
          resolved_target_index="${resolved_target_index}-${issue_id}-${timestamp}"
        elif [ "${pre_ga}" = "true" ]; then
          if [ -z "${product_name}" ] || [ -z "${product_version}" ]; then
            echo "Pre-GA releases require 'fbc.productName' and 'fbc.productVersion' set in the " \
                 "ReleasePlanAdmission spec.data field"
            exit 1
          fi
          resolved_target_index="${resolved_target_index}-${product_name}-${product_version}-${timestamp}"
        fi

        # Collect all fragments directly
        batch_fragments='[]'
        for((i=0; i<LENGTH; i++)); do
          fbc_fragment=$(jq -cr --argjson i "$i" '.components[$i].containerImage' "${SNAPSHOT_PATH}")
          batch_fragments=$(jq --arg fragment "$fbc_fragment" '. += [$fragment]' <<< "$batch_fragments")
        done

        # Use universal values from pipeline parameters directly
        batch_from_index="$(params.fromIndex)"
        batch_target_index="$resolved_target_index"
        batch_ocp_version="$(params.ocpVersion)"
        
        echo "Batch details:"
        echo "  - fromIndex: $batch_from_index"
        echo "  - targetIndex: $batch_target_index"
        echo "  - ocpVersion: $batch_ocp_version (validated across all fragments)"
        echo "  - fragments: $LENGTH items"
        
        # Calculate timeout for this batch
        finally_task_timeout=300
        pipeline_timeout=$(date -u "+%Hh%Mm%Ss" -d @$(( request_timeout_seconds + finally_task_timeout )))
        task_timeout=$(date -u "+%Hh%Mm%Ss" -d @$(( request_timeout_seconds )))

        # Create single batched InternalRequest for all components
        echo "Creating batched InternalRequest for $LENGTH fragments..."
        internal-request --pipeline "update-fbc-catalog" \
            -p fromIndex="${batch_from_index}" \
            -p targetIndex="${batch_target_index}" \
            -p fbcFragments="$(printf '%s' "${batch_fragments}" | jq -c .)" \
            -p iibServiceAccountSecret="${iib_service_account_secret}" \
            -p publishingCredentials="${publishing_credentials}" \
            -p buildTimeoutSeconds="${build_timeout_seconds}" \
            -p buildTags="$(jq -c . <<< "${build_tags}")" \
            -p addArches="$(jq -c . <<< "${add_arches}")" \
            -p hotfix="${hotfix}" \
            -p stagedIndex="${staged_index}" \
            -p taskGitUrl="$(params.taskGitUrl)" \
            -p taskGitRevision="$(params.taskGitRevision)" \
            --service-account "${internal_request_service_account}" \
            -l ${pipelinerun_label}="$(params.pipelineRunUid)" \
            --pipeline-timeout "${pipeline_timeout}" \
            --task-timeout "${task_timeout}" \
            -t "${request_timeout_seconds}" |tee "$(params.dataDir)"/ir-"$(context.taskRun.uid)"-batch-output.log

        internalRequest=$(awk -F"'" '/created/ { print $2 }' \
          "$(params.dataDir)"/ir-"$(context.taskRun.uid)"-batch-output.log)
        echo "Batch request created: ${internalRequest}"

        # Fetch batched results
        results=$(kubectl get internalrequest "${internalRequest}" -o jsonpath='{.status.results}')
        echo "${results}" > "$(params.dataDir)/ir-$(context.taskRun.uid)-batch-result.json"

        # Decompress jsonBuildInfo for processing
        decompressed_json_build_info="$(jq -r '.jsonBuildInfo' <<< "${results}" | base64 -d | gunzip)"
        completion_time_raw="$(jq -r '.updated' <<< "${decompressed_json_build_info}")"
        completion_time=$(date +"${timestamp_format}" -d "${completion_time_raw}")
        
        # Process results for each fragment in the batch
        fragment_count=$(jq -r 'length' <<< "$batch_fragments")
        
        for((f=0; f<fragment_count; f++)); do
          fragment=$(jq -r --argjson f "$f" '.[$f]' <<< "$batch_fragments")
          
          echo "Processing result for fragment: $fragment"
          
          # Build individual component result
          build_results=$(jq \
            --arg fragment "$fragment" \
            --arg target_index "$batch_target_index" \
            --arg ocp_version "$batch_ocp_version" \
            --arg completion_time "$completion_time" \
            --argjson decompressed_json "${decompressed_json_build_info}" \
          '{
            "fbc_fragment": $fragment,
            "target_index": $target_index,
            "ocp_version": $ocp_version,
            "image_digests": (.indexImageDigests | split(" ") | del(.[] | select(. == ""))),
            "index_image": $decompressed_json.index_image,
            "index_image_resolved": $decompressed_json.index_image_resolved,
            "completion_time": $completion_time,
            "iibLog": .iibLog
          }' <<< "${results}")

          # Add to results file
          export build_results
          yq -i '.components += [ env(build_results) ]' "$RESULTS_FILE"
        done

        # Extract flags from batch results (same for all fragments in batch)
        mustSignIndexImage=$(jq -r '.genericResult | fromjson' <<< "${results}" \
          | jq -r '.sign_index_image' |tr -d "\n")
        mustPublishIndexImage=$(jq -r '.genericResult | fromjson' <<< "${results}" \
          | jq -r '.publish_index_image' |tr -d "\n")
        fbc_opt_in=$(jq -r '.genericResult | fromjson' <<< "${results}" | jq -cr '.fbc_opt_in')

        # Store the results in Tekton's results files
        echo -en "${mustPublishIndexImage}" | tee "$(results.mustPublishIndexImage.path)"
        echo -en "${mustSignIndexImage}" | tee "$(results.mustSignIndexImage.path)"
        echo -en "${fbc_opt_in}" | tee "$(results.isFbcOptIn.path)"

        # Store deprecated results for compatibility
        conditions=$(kubectl get internalrequest "${internalRequest}" \
          -o jsonpath='{.status.conditions[?(@.type=="Succeeded")]}')
        jq '.reason // "Unset"'  <<< "${conditions}" | tee "$(results.requestReason.path)"
        jq '.message // "Unset"' <<< "${conditions}" | tee "$(results.requestMessage.path)"
        jq -r '.indexImageDigests' <<< "${results}" |  tee "$(results.indexImageDigests.path)"

        # Output batch logs for debugging
        jq -r '.iibLog' <<< "${results}"
        RC="$(jq -r '.exitCode' <<< "${results}")"

        # Summarize batch results
        if [ "$mustPublishIndexImage" = "true" ]; then
          echo "Index image will be published."
        elif [ "$fbc_opt_in" = "false" ]; then
          echo "Index image will not be published because fbc_opt_in is set to false in Pyxis."
          echo "If this is the first time you are releasing, make sure you request fbc_opt_in in Pyxis."
        elif [ "${staged_index}" = "true" ]; then
          echo "Index image will not be published because this is a staging release."
        else
          echo "Index image will not be published for an unspecified reason."
        fi

        if [ "$RC" -ne 0 ]; then
          echo "Batch processing failed, check the batch logs above to understand the reason"
          exit "$RC"
        fi
        
        echo "Batch processing completed successfully with $LENGTH components"
        echo "Results file:"
        cat "$RESULTS_FILE"
    - name: create-trusted-artifact
      computeResources:
        limits:
          memory: 128Mi
        requests:
          memory: 128Mi
          cpu: 250m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/create-trusted-artifact/create-trusted-artifact.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
