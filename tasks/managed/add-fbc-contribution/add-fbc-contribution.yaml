---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: add-fbc-contribution
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: |-
    Task to create an internalrequest to add fbc contributions to index images
  params:
    - name: snapshotPath
      description: Path to the JSON string of the mapped Snapshot spec in the data workspace
      type: string
    - name: dataPath
      description: Path to the JSON string of the merged data to use in the data workspace
      type: string
    - name: fromIndex
      type: string
      description: fromIndex value updated by update-ocp-tag task
    - name: targetIndex
      type: string
      description: targetIndex value updated by update-ocp-tag task
    - name: pipelineRunUid
      type: string
      description: The uid of the current pipelineRun. Used as a label value when creating internal requests
    - name: ocpVersion
      type: string
      description: The OCP version for all components in this release
    - name: resultsDirPath
      type: string
      description: Path to the results directory in the data workspace
    - name: ociStorage
      description: The OCI repository where the Trusted Artifacts are stored
      type: string
      default: "empty"
    - name: ociArtifactExpiresAfter
      description: Expiration date for the trusted artifacts created in the
        OCI repository. An empty string means the artifacts do not expire
      type: string
      default: "1d"
    - name: trustedArtifactsDebug
      description: Flag to enable debug logging in trusted artifacts. Set to a non-empty string to enable
      type: string
      default: ""
    - name: orasOptions
      description: oras options to pass to Trusted Artifacts calls
      type: string
      default: ""
    - name: sourceDataArtifact
      type: string
      description: Location of trusted artifacts to be used to populate data directory
      default: ""
    - name: dataDir
      description: The location where data will be stored
      type: string
      default: /var/workdir/release
    - name: taskGitUrl
      type: string
      description: The url to the git repo where the release-service-catalog tasks and stepactions to be used are stored
    - name: taskGitRevision
      type: string
      description: The revision in the taskGitUrl repo to be used
    - name: maxBatchSize
      type: string
      description: Maximum number of FBC fragments to process in a single batch
      default: "5"
    - name: validationResults
      type: string
      description: JSON containing pre-determined validation results from prepare-fbc-parameters task
      default: ""
  results:
    - name: buildTimestamp
      description: Build timestamp used in the tag
    - name: mustSignIndexImage
      description: Whether the index image should be signed
    - name: mustPublishIndexImage
      description: Whether the index image should be published
    - name: isFbcOptIn
      description: Indicates whether the FBC fragment is opt-in (true/false)
    - name: requestTargetIndex
      description: The targetIndex used in this request
    - name: requestResultsFile
      description: Internal Request results file
    - name: internalRequestResultsFile
      description: Additional Internal Request results file
    - name: requestMessage
      description: Internal Request message
    - name: requestReason
      description: Internal Request reason
    - name: indexImageDigests
      description: list of manifest digests for each arch from manifest list in index image
    - name: sourceDataArtifact
      type: string
      description: Produced trusted data artifact
  volumes:
    - name: workdir
      emptyDir: {}
  stepTemplate:
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
    env:
      - name: IMAGE_EXPIRES_AFTER
        value: $(params.ociArtifactExpiresAfter)
      - name: "ORAS_OPTIONS"
        value: "$(params.orasOptions)"
      - name: "DEBUG"
        value: "$(params.trustedArtifactsDebug)"
  steps:
    - name: use-trusted-artifact
      computeResources:
        limits:
          memory: 64Mi
        requests:
          memory: 64Mi
          cpu: 30m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/use-trusted-artifact/use-trusted-artifact.yaml
      params:
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(params.sourceDataArtifact)
    - name: add-contribution
      image: quay.io/konflux-ci/release-service-utils:0f82be4be43294b6a96846d87ef7f7c0b9e34267
      computeResources:
        limits:
          memory: 512Mi
        requests:
          memory: 512Mi  # was exiting with code 137 when set to 256Mi
          cpu: 200m
      script: |
        #!/usr/bin/env bash
        #
        set -eo pipefail

        SNAPSHOT_PATH="$(params.dataDir)/$(params.snapshotPath)"
        DATA_FILE="$(params.dataDir)/$(params.dataPath)"
        if [ ! -f "${DATA_FILE}" ] ; then
            echo "No valid data file was provided."
            exit 1
        fi

        # adding a new result as modifying the current one used breaks e2e for single component.
        # to be handled in RELEASE-1640.
        RESULTS_FILE="$(params.resultsDirPath)/internal-requests-results.json"
        echo -n "$RESULTS_FILE" > "$(results.internalRequestResultsFile.path)"
        RESULTS_FILE="$(params.dataDir)/$(params.resultsDirPath)/internal-requests-results.json"

        echo -n "$(params.dataDir)/$(params.pipelineRunUid)/ir-$(context.taskRun.uid)-result.json" \
          > "$(results.requestResultsFile.path)"

        default_build_timeout_seconds="3600"
        default_request_timeout_seconds="3600"

        staged_index=$(jq -r '.fbc.stagedIndex // "false"' "${DATA_FILE}")
        build_timeout_seconds=$(jq -r --arg build_timeout_seconds ${default_build_timeout_seconds} \
            '.fbc.buildTimeoutSeconds // $build_timeout_seconds' "${DATA_FILE}")
        request_timeout_seconds=$(jq -r --arg request_timeout_seconds ${default_request_timeout_seconds} \
            '.fbc.requestTimeoutSeconds // $request_timeout_seconds' "${DATA_FILE}")
        internal_request_service_account=$(jq -r '.fbc.internalRequestServiceAccount // "release-service-account"' \
            "${DATA_FILE}")

        if [ "${staged_index}" = "true" ]; then
          iib_service_account_secret="iib-service-account-stage"
        else
          iib_service_account_secret="iib-service-account-prod"
        fi
        publishing_credentials=$(jq -r '.fbc.publishingCredentials // "catalog-publishing-secret"' "$DATA_FILE")

        timestamp_format=$(jq -r '.fbc.timestampFormat // "%s"' "${DATA_FILE}")
        timestamp=$(date "+${timestamp_format}")

        # Extract results from prepare-fbc-parameters
        validation_results="$(params.validationResults)"
        if [ -n "${validation_results}" ] && [ "${validation_results}" != "null" ]; then
          echo "INFO: Using pre-determined results from prepare-fbc-parameters:"
          echo "${validation_results}" | jq .

          # Extract target index components
          sanitized_tag=$(jq -r '.sanitizedTag // ""' <<< "${validation_results}")
          if [ -n "$sanitized_tag" ] && [ "$sanitized_tag" != "null" ]; then
            # Replace the existing tag with the sanitized tag
            base_repo=$(echo "$(params.targetIndex)" | cut -d: -f1)
            target_index="${base_repo}:${sanitized_tag}"
            echo "INFO: Using sanitized tag: ${sanitized_tag}"
          else
            target_index="$(params.targetIndex)"
            echo "INFO: Using standard target index"
          fi

          # Extract publishing decisions
          mustPublishIndexImage=$(jq -r '.mustPublishIndexImage' <<< "${validation_results}")
          mustSignIndexImage=$(jq -r '.mustSignIndexImage' <<< "${validation_results}")
          fbcOptIn=$(jq -r '.fbcOptIn' <<< "${validation_results}")

          # Convert fbcOptIn to mustOverwriteFromIndexImage (same logic as before)
          if [ "${fbcOptIn}" = "true" ]; then
            mustOverwriteFromIndexImage="true"
          else
            mustOverwriteFromIndexImage="false"
          fi

          echo "INFO: Publishing decisions:"
          echo "  - mustPublishIndexImage: ${mustPublishIndexImage}"
          echo "  - mustSignIndexImage: ${mustSignIndexImage}"
          echo "  - mustOverwriteFromIndexImage: ${mustOverwriteFromIndexImage}"
        else
          target_index="$(params.targetIndex)"
          mustPublishIndexImage="true"
          mustSignIndexImage="true"
          mustOverwriteFromIndexImage="true"
          fbcOptIn="true"
          echo "INFO: No validation results provided, using defaults"
        fi

        # to keep compatibility with current single component mode
        echo -n "$timestamp" > "$(results.buildTimestamp.path)"
        echo -n "$target_index" > "$(results.requestTargetIndex.path)"
        jq -n --arg target_index "$target_index" \
          '{"index_image": {"target_index": $target_index}, "components": []}' \
          | tee "$RESULTS_FILE"

        pipelinerun_label="internal-services.appstudio.openshift.io/pipelinerun-uid"

        # Create batches with size limits
        LENGTH=$(jq -r '.components | length' "${SNAPSHOT_PATH}")
        MAX_BATCH_SIZE="$(params.maxBatchSize)"
        echo "Processing $LENGTH components with maximum batch size of $MAX_BATCH_SIZE..."

        # Read global buildTags and addArches from data file
        build_tags=$(jq '.fbc.buildTags // []' "${DATA_FILE}")
        add_arches=$(jq '.fbc.addArches // []' "${DATA_FILE}")

        # Use the same target_index for batch processing (already resolved above)
        resolved_target_index="$target_index"

        # Calculate number of batches needed
        NUM_BATCHES=$(( (LENGTH + MAX_BATCH_SIZE - 1) / MAX_BATCH_SIZE ))
        echo "Creating $NUM_BATCHES batch(es) for $LENGTH components"

        # Common values for all batches
        batch_from_index="$(params.fromIndex)"
        batch_target_index="$resolved_target_index"
        batch_ocp_version="$(params.ocpVersion)"
        
        # Calculate timeout for batches
        finally_task_timeout=300
        pipeline_timeout=$(date -u "+%Hh%Mm%Ss" -d @$(( request_timeout_seconds + finally_task_timeout )))
        task_timeout=$(date -u "+%Hh%Mm%Ss" -d @$(( request_timeout_seconds )))

        # Initialize the current fromIndex for chaining batches
        current_from_index="$batch_from_index"
        
        # Process each batch sequentially, chaining index images
        for((batch_num=0; batch_num<NUM_BATCHES; batch_num++)); do
          start_idx=$((batch_num * MAX_BATCH_SIZE))
          end_idx=$(((batch_num + 1) * MAX_BATCH_SIZE))
          if [ $end_idx -gt "$LENGTH" ]; then
            end_idx=$LENGTH
          fi
          batch_size=$((end_idx - start_idx))

          echo "Processing batch $((batch_num + 1))/$NUM_BATCHES (components $((start_idx + 1))-$end_idx)"

          # Collect fragments for this batch
          batch_fragments='[]'
          for((i=start_idx; i<end_idx; i++)); do
            fbc_fragment=$(jq -cr --argjson i "$i" '.components[$i].containerImage' "${SNAPSHOT_PATH}")
            batch_fragments=$(jq --arg fragment "$fbc_fragment" '. += [$fragment]' <<< "$batch_fragments")
          done

          echo "Batch $((batch_num + 1)) details:"
          echo "  - fromIndex: $current_from_index"
          echo "  - targetIndex: $batch_target_index"
          echo "  - ocpVersion: $batch_ocp_version"
          echo "  - fragments: $batch_size items"
          if [ $batch_num -gt 0 ]; then
            echo "  - Chaining from previous batch output"
          fi

          # Create InternalRequest for this batch
          echo "Creating InternalRequest for batch $((batch_num + 1)) with $batch_size fragments..."
          internal-request --pipeline "update-fbc-catalog" \
              -p fromIndex="${current_from_index}" \
              -p targetIndex="${batch_target_index}" \
              -p fbcFragments="$(printf '%s' "${batch_fragments}" | jq -c .)" \
              -p iibServiceAccountSecret="${iib_service_account_secret}" \
              -p publishingCredentials="${publishing_credentials}" \
              -p buildTimeoutSeconds="${build_timeout_seconds}" \
              -p buildTags="$(jq -c . <<< "${build_tags}")" \
              -p addArches="$(jq -c . <<< "${add_arches}")" \
              -p mustPublishIndexImage="${mustPublishIndexImage}" \
              -p mustSignIndexImage="${mustSignIndexImage}" \
              -p mustOverwriteFromIndexImage="${mustOverwriteFromIndexImage}" \
              -p taskGitUrl="$(params.taskGitUrl)" \
              -p taskGitRevision="$(params.taskGitRevision)" \
              --service-account "${internal_request_service_account}" \
              -l ${pipelinerun_label}="$(params.pipelineRunUid)" \
              --pipeline-timeout "${pipeline_timeout}" \
              --task-timeout "${task_timeout}" \
              -t "${request_timeout_seconds}" \
              |tee "$(params.dataDir)"/ir-"$(context.taskRun.uid)"-batch-$((batch_num + 1))-output.log

          # Store batch request info in global variables (final batch values will be used later)
          internalRequest=$(awk -F"'" '/created/ { print $2 }' \
            "$(params.dataDir)"/ir-"$(context.taskRun.uid)"-batch-$((batch_num + 1))-output.log)
          echo "Batch $((batch_num + 1)) request created: ${internalRequest}"

          # Fetch batch results (global variables updated each iteration)
          results=$(kubectl get internalrequest "${internalRequest}" -o jsonpath='{.status.results}')
          echo "${results}" > "$(params.dataDir)/ir-$(context.taskRun.uid)-batch-$((batch_num + 1))-result.json"

          # Decompress jsonBuildInfo for processing (global variable updated each iteration)
          decompressed_json_build_info="$(jq -r '.jsonBuildInfo' <<< "${results}" | base64 -d | gunzip)"
          completion_time_raw="$(jq -r '.updated' <<< "${decompressed_json_build_info}")"
          completion_time=$(date +"${timestamp_format}" -d "${completion_time_raw}")
          
          # Process results for each fragment in this batch
          fragment_count=$(jq -r 'length' <<< "$batch_fragments")
          
          for((f=0; f<fragment_count; f++)); do
            fragment=$(jq -r --argjson f "$f" '.[$f]' <<< "$batch_fragments")
            
            echo "Processing result for fragment: $fragment (batch $((batch_num + 1)))"
            
            # Build individual component result
            build_results=$(jq \
              --arg fragment "$fragment" \
              --arg target_index "$batch_target_index" \
              --arg ocp_version "$batch_ocp_version" \
              --arg completion_time "$completion_time" \
              --argjson decompressed_json "${decompressed_json_build_info}" \
            '{
              "fbc_fragment": $fragment,
              "target_index": $target_index,
              "ocp_version": $ocp_version,
              "image_digests": (.indexImageDigests | split(" ") | del(.[] | select(. == ""))),
              "index_image": $decompressed_json.index_image,
              "index_image_resolved": $decompressed_json.index_image_resolved,
              "completion_time": $completion_time,
              "iibLog": .iibLog
            }' <<< "${results}")

            # Add to results file
            export build_results
            yq -i '.components += [ env(build_results) ]' "$RESULTS_FILE"
          done
          
          # Update fromIndex for next batch (if there is one) to chain index images
          if [ $batch_num -lt $((NUM_BATCHES - 1)) ]; then
            # Extract the output index image from this batch to use as input for next batch
            next_from_index=$(jq -r '.index_image' <<< "$decompressed_json_build_info")
            if [ -n "$next_from_index" ] && [ "$next_from_index" != "null" ]; then
              current_from_index="$next_from_index"
              echo "Next batch will use fromIndex: $current_from_index"
            else
              echo "Warning: Could not extract index_image from batch $((batch_num + 1)) results, " \
                   "using original fromIndex"
            fi
          fi
        done

        # Use the publishing decisions we already extracted from prepare-fbc-parameters
        echo "Using publishing decisions from prepare-fbc-parameters:"
        echo "  - mustSignIndexImage: ${mustSignIndexImage}"
        echo "  - mustPublishIndexImage: ${mustPublishIndexImage}"
        echo "  - fbcOptIn: ${fbcOptIn}"

        # For backward compatibility, assign to legacy variable names
        fbc_opt_in="${fbcOptIn}"

        # Store the results in Tekton's results files
        echo -en "${mustPublishIndexImage}" | tee "$(results.mustPublishIndexImage.path)"
        echo -en "${mustSignIndexImage}" | tee "$(results.mustSignIndexImage.path)"
        echo -en "${fbc_opt_in}" | tee "$(results.isFbcOptIn.path)"

        # Store deprecated results for compatibility
        conditions=$(kubectl get internalrequest "${internalRequest}" \
          -o jsonpath='{.status.conditions[?(@.type=="Succeeded")]}')
        jq '.reason // "Unset"'  <<< "${conditions}" | tee "$(results.requestReason.path)"
        jq '.message // "Unset"' <<< "${conditions}" | tee "$(results.requestMessage.path)"
        jq -r '.indexImageDigests' <<< "${results}" |  tee "$(results.indexImageDigests.path)"

        # Output batch logs for debugging
        jq -r '.iibLog' <<< "${results}"
        RC="$(jq -r '.exitCode' <<< "${results}")"

        # Summarize batch results
        if [ "$mustPublishIndexImage" = "true" ]; then
          echo "Index image will be published."
        elif [ "$fbc_opt_in" = "false" ]; then
          echo "Index image will not be published because fbc_opt_in is set to false in Pyxis."
          echo "If this is the first time you are releasing, make sure you request fbc_opt_in in Pyxis."
        elif [ "${staged_index}" = "true" ]; then
          echo "Index image will not be published because this is a staging release."
        else
          echo "Index image will not be published for an unspecified reason."
        fi

        if [ "$RC" -ne 0 ]; then
          echo "Batch processing failed, check the batch logs above to understand the reason"
          exit "$RC"
        fi
        
        echo "Batch processing completed successfully with $LENGTH components"
        echo "Results file:"
        cat "$RESULTS_FILE"
    - name: create-trusted-artifact
      computeResources:
        limits:
          memory: 128Mi
        requests:
          memory: 128Mi
          cpu: 250m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/create-trusted-artifact/create-trusted-artifact.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
